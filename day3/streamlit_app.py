import streamlit as st
import os
import sys
from typing import Dict, Any, List
import time
from datetime import datetime

# Import our RAG system
from rag_langgraph import RAGLangGraph

# Configure Streamlit page
st.set_page_config(
    page_title="ğŸ¤– RAG Assistant",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

class StreamlitRAGApp:
    def __init__(self):
        self.setup_session_state()
        self.setup_sidebar()
        
    def setup_session_state(self):
        """Initialize session state variables."""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'rag_system' not in st.session_state:
            st.session_state.rag_system = None
        if 'api_keys_set' not in st.session_state:
            st.session_state.api_keys_set = False

    def setup_sidebar(self):
        """Setup sidebar with API keys and settings."""
        with st.sidebar:
            st.header("âš™ï¸ ì„¤ì •")
            
            # API Keys section
            st.subheader("ğŸ”‘ API í‚¤")
            
            openai_key = st.text_input(
                "OpenAI API Key", 
                type="password",
                value=os.environ.get("OPENAI_API_KEY", ""),
                help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            tavily_key = st.text_input(
                "Tavily API Key", 
                type="password", 
                value=os.environ.get("TAVILY_API_KEY", ""),
                help="ì›¹ ê²€ìƒ‰ì„ ìœ„í•œ Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            # Set environment variables
            if openai_key and tavily_key:
                os.environ["OPENAI_API_KEY"] = openai_key
                os.environ["TAVILY_API_KEY"] = tavily_key
                st.session_state.api_keys_set = True
                
                if st.session_state.rag_system is None:
                    with st.spinner("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
                        try:
                            st.session_state.rag_system = RAGLangGraph()
                            st.success("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
                        except Exception as e:
                            st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                            
            else:
                st.warning("ğŸ”‘ API í‚¤ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”")
                st.session_state.api_keys_set = False
            
            # Settings section
            st.subheader("ğŸ›ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
            
            if st.session_state.rag_system:
                max_retries = st.slider(
                    "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜", 
                    min_value=1, 
                    max_value=5, 
                    value=st.session_state.rag_system.MAX_RETRIES,
                    help="í• ë£¨ì‹œë„¤ì´ì…˜ ê°ì§€ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜"
                )
                st.session_state.rag_system.MAX_RETRIES = max_retries
            
            # Clear chat button
            if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì‚­ì œ", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
                
            # System info
            st.subheader("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
            st.caption("ğŸ“š ì§€ì› ì£¼ì œ: AI ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, LLM ê³µê²©")
            st.caption("ğŸ” ê²€ìƒ‰: ë²¡í„°ìŠ¤í† ì–´ + ì›¹ê²€ìƒ‰")
            st.caption("âœ… í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦ í¬í•¨")

    def display_message(self, message: Dict[str, Any]):
        """Display a single message in the chat."""
        with st.chat_message(message["role"]):
            if message["role"] == "assistant":
                # Display the answer
                st.markdown(message["content"])
                
                # Display sources if available
                if "sources" in message and message["sources"]:
                    st.markdown("---")
                    st.markdown("### ğŸ“š ì°¸ê³  ë¬¸í—Œ")
                    
                    for i, source in enumerate(message["sources"], 1):
                        source_type = "ğŸŒ ì›¹ê²€ìƒ‰" if source["type"] == "web_search" else "ğŸ“– ë¬¸ì„œ"
                        st.markdown(f"**{i}. {source_type}**: [{source['title']}]({source['url']})")
                
                # Display metadata if available
                if "metadata" in message:
                    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                        metadata = message["metadata"]
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("ì¬ì‹œë„ íšŸìˆ˜", metadata.get("retry_count", 0))
                        with col2:
                            st.metric("í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦", "âœ…" if metadata.get("hallucination_free", False) else "âŒ")
                        with col3:
                            st.metric("ì§ˆë¬¸ ë‹µë³€", "âœ…" if metadata.get("answers_question", False) else "âŒ")
            else:
                st.markdown(message["content"])

    def process_query_with_progress(self, question: str) -> Dict[str, Any]:
        """Process query with real-time progress updates."""
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        
        # Initialize progress tracking
        progress_steps = {
            "__start__": "ğŸ¯ ì§ˆë¬¸ ë¼ìš°íŒ… ì¤‘...",
            "retrieve": "ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...",
            "websearch": "ğŸŒ ì›¹ ê²€ìƒ‰ ì¤‘...",
            "grade_documents": "ğŸ“Š ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ì¤‘...",
            "generate": "âœ¨ ë‹µë³€ ìƒì„± ì¤‘...",
            "check_hallucinations": "ğŸ” í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦ ì¤‘...",
            "check_answer_quality": "âœ… ë‹µë³€ í’ˆì§ˆ í™•ì¸ ì¤‘...",
            "cannot_answer": "âŒ ë‹µë³€ ë¶ˆê°€ ì²˜ë¦¬ ì¤‘..."
        }
        
        progress_bar = progress_placeholder.progress(0)
        current_step = 0
        total_steps = len(progress_steps)
        
        try:
            app = st.session_state.rag_system.build_graph()
            inputs = {"question": question, "retry_count": 0, "source_references": []}
            
            # Stream the execution
            for i, output in enumerate(app.stream(inputs)):
                for key, value in output.items():
                    if key in progress_steps:
                        current_step = min(current_step + 1, total_steps)
                        progress = current_step / total_steps
                        progress_bar.progress(progress)
                        status_placeholder.info(f"ğŸ”„ {progress_steps[key]}")
                        time.sleep(0.3)  # Small delay for visual effect
            
            # Final result
            result = app.invoke(inputs)
            progress_bar.progress(1.0)
            status_placeholder.success("âœ… ì™„ë£Œ!")
            
            # Clear progress indicators after a moment
            time.sleep(1)
            progress_placeholder.empty()
            status_placeholder.empty()
            
            return result
            
        except Exception as e:
            progress_placeholder.empty()
            status_placeholder.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e

    def run(self):
        """Main app runner."""
        # Header
        st.title("ğŸ¤– RAG Assistant")
        st.markdown("*AI ì—ì´ì „íŠ¸, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, LLM ë³´ì•ˆì— ëŒ€í•œ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!*")
        
        # Check if system is ready
        if not st.session_state.api_keys_set:
            st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
            st.stop()
        
        if st.session_state.rag_system is None:
            st.error("RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # Display chat messages
        for message in st.session_state.messages:
            self.display_message(message)
        
        # Chat input
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: 'LLMì— ëŒ€í•œ ê³µê²© ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?')"):
            # Add user message
            user_message = {"role": "user", "content": prompt}
            st.session_state.messages.append(user_message)
            self.display_message(user_message)
            
            # Generate assistant response
            with st.chat_message("assistant"):
                try:
                    # Process query with progress tracking
                    result = self.process_query_with_progress(prompt)
                    
                    # Extract response and metadata
                    answer = result.get("generation", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    sources = result.get("source_references", [])
                    
                    # Display answer
                    st.markdown(answer)
                    
                    # Display sources
                    if sources:
                        st.markdown("---")
                        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸í—Œ")
                        
                        for i, source in enumerate(sources, 1):
                            source_type = "ğŸŒ ì›¹ê²€ìƒ‰" if source["type"] == "web_search" else "ğŸ“– ë¬¸ì„œ"
                            st.markdown(f"**{i}. {source_type}**: [{source['title']}]({source['url']})")
                    
                    # Display metadata
                    with st.expander("ğŸ” ìƒì„¸ ì •ë³´"):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("ì¬ì‹œë„ íšŸìˆ˜", result.get("retry_count", 0))
                        with col2:
                            hallucination_free = result.get("hallucination_free", False)
                            st.metric("í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦", "âœ… í†µê³¼" if hallucination_free else "âŒ ê°ì§€")
                        with col3:
                            answers_question = result.get("answers_question", False)
                            st.metric("ì§ˆë¬¸ ë‹µë³€", "âœ… ì ì ˆí•¨" if answers_question else "âŒ ë¶€ì ì ˆí•¨")
                    
                    # Save assistant message
                    assistant_message = {
                        "role": "assistant",
                        "content": answer,
                        "sources": sources,
                        "metadata": {
                            "retry_count": result.get("retry_count", 0),
                            "hallucination_free": result.get("hallucination_free", False),
                            "answers_question": result.get("answers_question", False),
                            "timestamp": datetime.now().isoformat()
                        }
                    }
                    st.session_state.messages.append(assistant_message)
                    
                except Exception as e:
                    error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    
                    # Save error message
                    error_message = {
                        "role": "assistant",
                        "content": error_msg,
                        "sources": [],
                        "metadata": {"error": True, "timestamp": datetime.now().isoformat()}
                    }
                    st.session_state.messages.append(error_message)

def main():
    """Main function to run the Streamlit app."""
    app = StreamlitRAGApp()
    app.run()

if __name__ == "__main__":
    main()